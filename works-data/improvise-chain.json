{
  "id": "improvise-chain",
  "title": "Improvise±Chain",
  "category": "code",
  "year": "2022",
  "thumbnail": "../image/improvise_chain/Improvise_chain01.jpg",
  "images": [
    "../image/improvise_chain/Improvise_chain01.jpg",
    "../image/improvise_chain/Improvise_chain02.jpg",
    "../image/improvise_chain/Improvise_chain03.jpg"
  ],
  "description": "《Improvise+=Chain》は，音楽生成人工知能による，ピアノ・ギター・ベース・ドラムの4パートのリアルタイム生成パフォーマンスである．<br><br>次々に新たな演奏を即興で披露する各パートは，常に他パートの演奏に注意を傾け，情報をやり取りし，相互に影響し合いながら演奏する．各スピーカーに繋がれた光の線は，その情報の量を表わす．<br>人間のミュージシャンによる即興演奏（Improvisation）では，各々の楽器の演奏に加え，表情，息遣い，アイコンタクトなどの高次な情報によるミュージシャン同士のコミュニケーションが常時行なわれ，時折それは生命であるかのように不確実な振る舞いを見せる．<br>人間の創造的行為と機械による（人間による創作物の大量のデータを介した）模倣の間にある相違として，決定性が挙げられる．創造的人工知能の多くは擬似的な無作為性をもってその創作にヴァリエーションをもたせているが，そこに本質的な不確実性はないといっていい．<br>複数の創造主間のインタラクションによって為され，ダイナミックな不確実性を持つ即興演奏において，その違いはより明白になるはずである．<br><br>本作品では，約1500曲のデータを学習した190万パラメータの深層学習モデル（Transformer Decoder）を用いて，コンピュータによる人間の即興演奏の模倣を試みる．人間と異なり，音楽生成モデルには空間的・時間的情報を感知する能力はなく，鑑賞者にどう見えるかに関わらずその内部は決定的なアルゴリズム（疑似乱数による確率のモデリング）である．その振る舞いはどう人間のミュージシャンたちと異なるのか，そしてそれから見いだせる音楽的な価値は何かを，体験を通して探る．<br>",
  "credit": "Research & Development: Atsuya Kobayashi<br>Concept Design: Atsuya Kobayashi<br>Visualization : Ryo Simon<br>Filming : Asuka Ishii, Kazufumi Shibuya",
  "tools": "TouchDesigner / Ableton Live",
  "link": "<a class=\"list\" href=\"https://www.ntticc.or.jp/ja/archive/works/improvise-chain/\"> ICC </a> / <a class=\"list\" href=\"https://cclab.sfc.keio.ac.jp/2024/02/09/improvisechain-listening-to-the-ensemble-improvisation-of-an-autoregressive-generative-model/\"> CCLab Homepage </a>",
  "exhibition": null,
  "award": null,
  "paper": "<a class=\"list\" href=\"https://nime.org/proc/nime2023_94/\">New Interfaces for Musical Expression</a>",
  "grants": null,
  "collaborators": null,
  "performers": null,
  "download": null,
  "citation": null,
  "related": null
}
